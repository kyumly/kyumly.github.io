---
layout : single-3
title : "VGG 논문 리뷰"
categories : CNN
tag : [python, AI, CNN]
toc : true
toc_sticky : true
author_profile : false
use_math : true
---
Very Deep Convolutional Networks for large-scale image recognition(VGG) 논문 리뷰

# 1. Introduction

- ConvNet large-scale image 그리고 video recognition 분야에서 성공하게 된다
- 성공이 된 이유는 대규모 이미지를 public 하게 접근이 가능하고, GPU 또는 대규모 분산 클러스터와 같은 고성능 컴퓨터 시스템을 사용하능해 성공이됨
- 특히 deep visual recognition 아키턱처에 있어 중요한 역할은 ImageNet 대규모 인식 챌린지에 의해 수행됬고, 몇 세대 걸친 대규모 이미지 분류 시스템의 테스트베드 역할을 하게 된다

- Computer vision 영역에서 ConvNets은 점점 중요해지고 있다. 그래서 원래 출시된 (AlexNet) 같은 아키텍처들을 향싱시키기 위해 노력하기 시작했다.
- 예를들어 더 작은 receptive field 사용하거나, 작은 stride를 사용했다. 또 다른 방법으로는 스케일을 조정하여 train, test 여러번 실행하는 것이다.
- 매우 작은 필드(3 * 3)를 사용해 우리는 depth 디자인하여 성능을 높일 것이다.


# 2. ConvNet Configurations

## 2.1 ARCHITECTURE

훈련하는 동안에는 ConvNet 입력 사이즈는 (224 * 244, 3) (RGB) 사용한다, 데이터 전처리 과정에서는 RGB에 대한 평균을 뺄것이다.<br>
이미지는 Conv 지나서, 사용되는 필터는 receptive field는 (3, 3) 사용한다. (3,3 필터는 상하/좌우, 중앙의 픽셀 값들을 파악할 수 있는 가장 작은 단위이다.)<br>
또한 한가지는 유용하게사용되는 필터는 (1,1) conv filters 이며, (1,1) 필터는 입력 채널의 선형 변환으로 사용하면 좋다.<br>
보폭은 1로 고정되어 사용하고, 패딩은 공간적인 패딩을 사용한다.<br>
layer input conv 실행이 된다해도 input layer size, out layer size 같아야한다. 즉 input size 유지되어야 한다. 그레서 패딩으로 필터가 (3, 3)을 사용하면 padding은 1을 주고 공간을 유지해야 한다.<br>
spatial pooling 5번을 총 전달하게 된다,

***정리***
- 데이터 전처리 과정에서는 RGB 평균을 빼는 역할을 한다.
- receptive field 크기(3,3 )가 작아야 상하/좌우, 중앙에 있는 값들을 인식할 수 있다. 하지만 (1,1) 필터는 conv layer flatten 하는 역할을 지니고 있다.
- stride 1로 고정하여 사용하고 패딩은 input layer 공간을 유지하는 방향으로 설계된다
- pooling 총 5번 사용한다. pooling 종류는 max pooling 사이즈 (2,2) stride 2를 함께 사용하게 된다.


Conv layers stack은 3개의 FC layer 쌓게 된다.<br>
첫번째, 두번째 4096 채널(뉴런)을 각각 가지고 있다. 그리고 세번째 layer는 1000개의 classification 그리고 1000의 채널을 가지게 된다(각각이 class(label))<br>
마지막에서는 softmax layer를 사용하게된다.<br>

***정리***
- Conv 마지막 단계에서는 fully-connected를 사용하여 연결하게 된다
- 첫 번째, 두 번째 layer에서는 뉴런의 수는 4096개의 뉴런을 사용한다
- 마지막 layer는 1000개의 뉴런을 사용하지만, 각각이 class 점수라고 생각하면 된다
- 그리고 activation funtion에서는 softmax 사용한다.

모든 hidden layers 에서는 relu(비선형 함수) 사용한다.
네티워크 과정에서는 LRN(Local Response Normalization) 정규화를 포함하지 않는다는 것을 알아야한다.
세션 4에서 볼 수 있겠지만, normalisation 성능을 향상 시키지는 않고 메모리 사용과 학습 시간을 오히려 증가 시킨다.

***정리***
- 모든 hidden layer 에서는 비선형 함수인 relu 사용하고
- 네트워크 모든 과정에서는 local response Normalization 사용하지 않는다. 이유는 성능 향상은 없는데 메모리 사용량은 증가하고 학습시간이 증가하기 떄문이다.


## 2.2 CONFIGURATIONS
Conv Configurations (평가된 종이) table1에 간단하게 설명되어 있다.<br>
컬럼들에 이름을 (A - E) 이름을 사용할 것이다.<br>
기본적인 디자인은 Sect 2.1 그리고 다른 Layer 11(Conv 8, FC 3) A 부터 19(CONV 16, FC 3) E까지 사용한다.
width (채널) 첫번째 weight는 64 그리고  증가한다 2의 배수식 마지막으로 512까지 간다. max pooling을 사용하여 2배씩 줄이게된다.


***정리***
- table1에 간단하게정리 되어 있다
- 네이밍은 A ~ E 까지 사용되고
- 기본적인 디자인 정보는 Sect 2.1 가서 보면 된다. layer 11 (Conv 8, FC 3 : A) 부터 layer 19 (Conv 16, FC 3 : E)까지 사용된다
- width 첫번째 채널은 64를 사용하고 2배식 증가한다. 5개의 max pooling 사용해 scale를 조정하게 된다.



## 2.3 DISCUSSION
![kyumly]({{site.url}}/images/basic/vgg-img2.png){: .align-center .img-width-half}


layer (7,7) 필터는 효과적인 필터이다. 하지만 우리는 사용할 필터는 (3,3)을 여러개 쌓아서 사용한다.<br>
왜 (7,7) 필터 대신 사용할까?<br>
첫째, 우리는 하나의 레이어 대신 세 개의 레이어를 통합하여 기능을 더 차별적으로 만듭니다.<br>
두번째, 우리는 수 많은 파라미터를 증가 시킨다. 한번 가정해보자 input 그리고 output three-layer 3 * 3 convNet 쌓고 같은 채널 C를 가지고 있다.<br>
그리고 그 스택안에 있는 파라미터는 3 x (3 x 3 x C x C) = 27C^2 된다. <br>
만약  7 * 7 필터를 사용한다면 (7x7xCxC) = 47*c^2 된다<br>
즉 7 x 7 필터를 사용하면 81프로 정도 증가하게된다. 

***정리***
- 3 x 3 필터를 사용하면 7 x 7 필터보다 작은 파라미터 값을 얻을 수 있다.

C는 [1 X 1] 필터를 사용한 흔적이 있다. [1 X 1] 필터는 receptive fields 없이 결정함수의 비선형성을 증가시킬 것이다. <br>
[1 X 1] 컨볼루션이 본질적으로 동일한 차원성(입력 채널과 출력 채널의 수가 동일함)의 공간에 대한 선형 투영이지만, 함수에 의해 추가적인 비선형성이 도입이 됩니다.


**정리**
- [1 X 1] 사용하게 된다면, 비선형성 함수를 전역으로 실행시킬 수 있다. 


![kyumly]({{site.url}}/images/basic/vgg-img1.png){: .align-center .img-width-half}


# 3. Classification Framework
앞에서는 네트워크 설정에 대해 설명했다. 이번 세션에서는 우리는 분류에 대해 자세히 설명하고 훈련 방법과 평가방법을 설명하겠다.

## 3.1 Training
ConvNet 훈련 방법으로는 Krizhevsky 방식을 따라한다.
즉 그 훈련은 미니배치 경사하강법(SGD + momentum) 사용하는 목적 다항 로지스틱 회귀 목표 최적하여 훈련을 실행한다.
배치 사이즈는 256를 사용하고, momentum은 0.9로 설정한다.
훈련 하는 과정에서 가중치 규제는 (L2, 알파 곱셈은 5*10^-4) 그리고 FC 시작되는 2개의 계층에서는 0.5 비율을 설정한다.
LR 비율은 10^-2 설정하고,검증 세트 정확도가 향상되지 않는다면 10배수식 감소시킨다.
총 합습률을 3번 감소시키고, 370K(74 epochs) 번의 반복 후 합습을 중단했다.
우리는 (Krizhevsky 등, 2012)와 비교하여 더 많은 파라미터와 더 깊은 네트워크를 사용하였지만,
네트워크가 수렴하는 데 더 적은 에포크가 필요했을 것으로 추측합니다.
이는 (a) 더 큰 깊이와 더 작은 컨볼루션 필터 크기로 인해 부과된 암묵적 정규화, (b) 특정 레이어의 사전 초기화로 인해 발생한 것으로 생각합니다.

**정리**
- ConvNet 훈련 방법으로는 Krizhevsky 방식을 사용했다.
- SGD + momentum 사용하여 최적화를 진행했고, 목적 다항 로지스틱회귀를 사용한다.
- 훈련하는 과정에서 배치 사이즈는 256, momentum 0.9를 사용한다.
- 가중치 훈련 규제는 L2, 곱셉은 5 × 10^-4 설정했다. FC 첫번째와 두번째 layer는 0.5 dropout 실행했다.
- LR 비율은 10^-2 사용해 검증데이터에 대한 정확도가 안높아진다면 10 배율식 감소시켰다.
- 총 합습률을 3번정도 감소시키고 74 에포크 후 훈련이 종료되었다
-  Krizhevsky 보다 적은 더 많은 파라미터와 깊은 네트워크를 사용했지만, 더 적은 에프로를 발생시켰다.

***가중치 초기화*** 매우 중요하다, 왜냐하면 나쁜 초기화는 깊은 신경망에서 기울기의 불안정성으로 인해 학습이 정체될 수 있기 때문입니다.(기울기가 없어질 수 있다. cs231n 부분 참조)
이 문제를 피하기 위해 우리는 구성 A (표 1 참조)로 훈련을 시작했습니다. 
이 구성은 무작위 초기화로 훈련할 수 있는 충분히 얕은 구조였습니다. (얇은 구조에서는 상관이 없다??)
그런 다음, 더 깊은 아키텍처를 훈련할 때 첫 번째 네 개의 컨볼루션 레이어와 마지막 세 개의 완전 연결 레이어를 네트워크 A의 레이어로 초기화했습니다 (중간 레이어는 무작위로 초기화되었습니다).
사전 초기화된 레이어에 대한 학습률을 감소시키지 않았으며, 학습 중에 이 레이어가 변할 수 있도록 허용했습니다. 
무작위 초기화에 대한 경우 (적용 가능한 경우), 가중치는 평균이 0이고 분산이 10^-2인 정규 분포에서 샘플링되었습니다. 편향은 0으로 초기화되었습니다.  => 결국 평균이 0이고 분산이 10^2인 정규분포를 샘플링하여 사용해야한다.
논문 제출 이후, Glorot & Bengio (2010)의 무작위 초기화 절차를 사용하여 사전 훈련 없이 가중치를 초기화할 수 있다는 것을 발견하였습니다.

**정리**
- 가중치를 잘못 초기화할 시 역전파과정에서 가중치가 0으로 수렴할 수 있다.
- 하지만 얇은 구조에서는 상관 없음
- 정규분포를 사용해서 가중치를 초기화 시킴 



고정 크기인 224×224 픽셀 ConvNet 입력 이미지를 얻기 위해, 이들은 크기를 조절한 훈련 이미지에서 무작위로 잘라냈습니다 (SGD 반복당 하나의 잘라낸 영역).
훈련 세트를 더 보강하기 위해, 이러한 잘라낸 영역은 무작위로 수평으로 뒤집히거나 RGB 색상이 무작위로 변환되었습니다 (Krizhevsky 등, 2012). 
훈련 이미지 크기 조절에 대한 자세한 내용은 아래에서 설명되었습니다.


**training image size**

훈련 이미지 크기에 대한 설명입니다. 
훈련 이미지의 크기를 결정하기 위해, 우리는 이미지의 등방성 크기 조절된 훈련 이미지 중에서 ConvNet 입력을 잘라내는데 사용될 가장 작은 한 변을 나타내는 S를 고려합니다 (우리는 S를 훈련 스케일이라고도 부릅니다). 
잘라내는 크기는 224 × 224로 고정되어 있지만 원칙적으로 S는 224 이상의 어떤 값을 가질 수 있습니다. 
예를 들어, S = 224는 잘라낸 부분이 훈련 이미지의 가장 작은 한 변을 완전히 포괄하는 전체 이미지 통계를 캡처하게 됩니다. 
반면에 S ≫ 224인 경우, 잘라낸 부분은 이미지의 작은 부분을 나타내며, 작은 객체나 객체 부분을 포함하게 됩니다.<br>


우리는 훈련 스케일 S를 설정하는 두 가지 방법을 고려합니다. 
첫 번째 방법은 S를 고정하는 것으로, 이는 단일 스케일 훈련에 해당합니다 (참고로 샘플링된 잘라낸 영역 내의 이미지 내용은 여전히 다중 스케일 이미지 통계를 나타낼 수 있습니다).
실험에서는 두 가지 고정 스케일에서 훈련된 모델을 평가했습니다: S = 256 (이는 이전 연구에서 널리 사용되었습니다 (Krizhevsky 등, 2012; Zeiler & Fergus, 2013; Sermanet 등, 2014)) 및 S = 384. 
ConvNet 구성이 주어지면 먼저 S = 256으로 네트워크를 훈련시켰습니다. S = 384 네트워크의 훈련을 가속화하기 위해 S = 256으로 사전 훈련된 가중치로 초기화하고 초기 학습률을 10^-3으로 더 낮게 설정했습니다.<br>


두 번째 방법은 다중 스케일 훈련입니다. 
이 경우 각 훈련 이미지는 S를 [Smin, Smax] 범위에서 무작위로 샘플링하여 개별적으로 크기를 조절합니다 (여기서 Smin = 256 및 Smax = 512를 사용했습니다).
이미지 내의 객체는 다양한 크기일 수 있으므로 훈련 중에 이를 고려하는 것이 유리합니다. 
이는 크기 흔들림(scale jittering)에 의한 훈련 세트 보강으로도 볼 수 있으며, 하나의 모델이 다양한 스케일 범위에서 객체를 인식하도록 훈련됩니다. 
속도 문제로 인해 우리는 다중 스케일 모델을 동일한 구성으로 사전 훈련된 단일 스케일 모델의 모든 레이어를 파인튜닝하여 훈련했습니다 (고정 S = 384로 사전 훈련된 모델).


## 3.2 test time
테스트 시간에는 훈련된 ConvNet과 입력 이미지가 주어졌을 때 다음과 같이 분류됩니다. 
먼저, 입력 이미지는 미리 정의된 가장 작은 이미지 한쪽 크기인 Q로 등방성으로 크기를 조절합니다 (이를 테스트 스케일이라고도 합니다). 여기서 주목할 점은 Q가 훈련 스케일 S과 반드시 동일하지 않아도 된다는 것입니다. 
(섹션 4에서 보여줄 것처럼 각 S에 대해 여러 Q 값을 사용하면 성능이 향상됩니다). 
그런 다음, 네트워크는 테스트 이미지를 다음과 같은 방식으로 조밀하게 적용합니다 (Sermanet 등, 2014와 유사한 방식입니다).
즉, 완전 연결 레이어는 먼저 컨볼루션 레이어로 변환됩니다 (첫 번째 FC 레이어는 7 × 7 컨볼루션 레이어로, 마지막 두 FC 레이어는 1 × 1 컨볼루션 레이어로). 
그 결과로 얻어진 완전 합성 네트워크는 전체 (자르지 않은) 이미지에 적용됩니다.
결과는 클래스 점수 맵으로 나타나며 채널 수는 클래스 수와 동일하며 입력 이미지 크기에 따라 가변적인 공간 해상도를 가지고 있습니다. 
마지막으로 이미지의 고정 크기 벡터의 클래스 점수를 얻기 위해 클래스 점수 맵은 공간 평균화 (총합 풀링)됩니다. 
또한 이미지의 수평 뒤집기로 테스트 세트를 보강하며, 원본 및 뒤집은 이미지의 소프트맥스 클래스 사후 확률을 평균하여 이미지의 최종 점수를 얻습니다.



완전 합성 네트워크가 전체 이미지에 적용되기 때문에 테스트 시간에 여러 개의 크롭을 샘플링할 필요가 없습니다 (Krizhevsky 등, 2012). 
이것은 각 크롭에 대해 네트워크를 다시 계산해야 하므로 효율적이지 않습니다. 
동시에 Szegedy 등 (2014)가 수행한 것처럼 많은 크롭 집합을 사용하는 것은 완전 합성 네트워크에 비해 입력 이미지를 더 미세하게 샘플링하므로 정확도 향상에 이바지할 수 있습니다.
또한, 멀티 크롭 평가는 밀집 평가와 상호 보완적입니다. 왜냐하면 다른 컨볼루션 경계 조건 때문입니다. 
크롭에 ConvNet을 적용할 때, 컨볼루션된 특징 맵은 제로 패딩으로 채워지지만 밀집 평가의 경우 동일한 크롭의 패딩은 이미지의 이웃 부분에서 자연적으로 발생합니다 (컨볼루션 및 공간 풀링 모두에서), 이로 인해 전체 네트워크 수용 영역이 크게 증가하므로 더 많은 맥락이 포착됩니다.
실제로 우리는 여러 크롭의 증가된 계산 시간이 정확도의 잠재적 이익을 정당화하지 않을 것이라고 믿지만 참고로 우리의 네트워크를 50개의 크롭 당 3개의 스케일에서 평가합니다 (2개의 뒤집기가 있는 5 × 5 정규 그리드로 총 150개의 크롭), 이는 Szegedy 등 (2014)가 사용한 4개의 스케일에 대한 144개 크롭과 비교 가능합니다.


## 3.3 IMPLEMENTATION DETAILS
우리의 구현은 공개적으로 이용 가능한 C++ Caffe 툴박스 (Jia, 2013)를 기반으로 하였으나 여러 가지 중요한 수정 사항이 포함되어 있습니다. 
이로써 우리는 단일 시스템에 설치된 여러 개의 GPU에서 훈련 및 평가를 수행할 수 있으며, 다중 스케일에서 (위에서 설명한대로) 전체 크기 (자르지 않은) 이미지에서 훈련 및 평가를 수행할 수 있습니다. 
멀티-GPU 훈련은 데이터 병렬화를 활용하며, 각 훈련 이미지 배치를 여러 개의 GPU 배치로 분할하여 각 GPU에서 병렬로 처리됩니다. GPU 배치의 그래디언트가 계산된 후, 그들은 전체 배치의 그래디언트를 얻기 위해 평균화됩니다. 
GPU 간의 그래디언트 계산은 동기적으로 이루어지므로, 결과는 단일 GPU에서 훈련하는 것과 완전히 동일합니다.
최근에는 ConvNet 훈련을 가속화하기 위한 더 정교한 방법들이 제안되었으며, 이러한 방법은 네트워크의 다른 레이어에 대해 모델 및 데이터 병렬화를 사용합니다 (Krizhevsky, 2014). 
그러나 우리는 개념적으로 훨씬 간단한 방법이 이미 단일 GPU 대비 4개의 GPU 시스템에서 3.75배의 가속을 제공한다는 것을 발견했습니다. 
네비디아 타이탄 블랙 GPU 4개가 장착된 시스템에서 하나의 네트워크를 훈련하는 데 걸리는 시간은 아키텍처에 따라 2~3주가 소요되었습니다.

# 4. Classification experiments
요기서는 image classification 결과를 보여줄 것이다.
데이터셋은 포함한다 1000개의 classes, 그리고 나눳다 train (1.3M 이미지), validation (50K 이미지) 그리고 테스트 (100K)
분류 수행은 2가지를 평가할 것이다. top-1 그리고 top5 error. 그 형식은 다중 클래스 분류에 error이다. 즉 정답이 없는 이미지의 비율을 나타낸다.
